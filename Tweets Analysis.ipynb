{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Twitter data analysis\n",
    "\n",
    "#Installing Packages\n",
    "#Run python files for oauth_login, twitterSearch and save_to_DB \n",
    "import tweepy\n",
    "import twitter\n",
    "import json\n",
    "import sys\n",
    "from twitter_login_fn import oauth_login\n",
    "from twitter_search_fn import twitterSearch\n",
    "from datetime import datetime\n",
    "from DB_fn import save_to_DB\n",
    "import pymongo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Setting up MongoDB \n",
    "#Making mongodb connection\n",
    "client = pymongo.MongoClient()\n",
    "client.database_names()\n",
    "\n",
    "#Creating database deletefacebook\n",
    "db1 = client.deletefacebook\n",
    "db1.collection_names()\n",
    "\n",
    "#Creating collection fb1 in deletefacebook database for tweets ranging from 10th April to 18th April 2018\n",
    "coll1 = db1.fb1\n",
    "docs= coll1.find()\n",
    "\n",
    "fblist = [doc for doc in docs]\n",
    "print(len(fblist))\n",
    "print(fblist[0])\n",
    "print(fblist[-500])\n",
    "\n",
    "#Creating second collection fb2 for the tweets of 10th and 11th April 2018\n",
    "coll2 = db1.fb2\n",
    "docs2= coll2.find()\n",
    "fblist2 = [doc for doc in docs2]\n",
    "print(len(fblist2))\n",
    "print(fblist2[0])\n",
    "print(fblist2[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Making a dataframe\n",
    "fbweekdata = pd.DataFrame()\n",
    "fbweekdata['id'] = [tweet['id'] for tweet in fblist]\n",
    "fbweekdata['text'] = [tweet['text'] for tweet in fblist]\n",
    "fbweekdata['created_at'] = [tweet['created_at'] for tweet in fblist]\n",
    "fbweekdata['retweeted?'] = [tweet['retweeted'] for tweet in fblist]\n",
    "fbweekdata['retweet_count'] = [tweet['retweet_count'] for tweet in fblist]\n",
    "fbweekdata['favorite_count'] = [tweet['favorite_count'] for tweet in fblist]\n",
    "fbweekdata['lang'] = [tweet['lang'] for tweet in fblist]\n",
    "fbweekdata['username'] = [tweet['user']['name'] for tweet in fblist]\n",
    "fbweekdata['usertimezone'] = [tweet['user']['time_zone'] for tweet in fblist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the list of countries from where tweets were posted\n",
    "countrylist = []\n",
    "count = 0\n",
    "for tweet in fblist:\n",
    "    if tweet['place'] != None:\n",
    "        countrylist.append( tweet['place']['country'])\n",
    "    else:\n",
    "        countrylist.append(None)\n",
    "        count += 1\n",
    "\n",
    "#adding country to fbweekdata\n",
    "fbweekdata['country'] = countrylist\n",
    "print(count)\n",
    "\n",
    "#getting the list of hashtags and saving it in Fbweekdata\n",
    "hashtaglist= []\n",
    "for tweet in fblist:\n",
    "    htags = [hashtag['text'] for hashtag in tweet['entities']['hashtags']]\n",
    "    hashtaglist.append(htags)\n",
    "fbweekdata['hashtags'] = hashtaglist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting a list of mentions and saving it in Fbweekdata\n",
    "mentionlist= []\n",
    "for tweet in fblist:\n",
    "    mentiontags = [user_mention['screen_name'] for user_mention in tweet['entities']['user_mentions']]\n",
    "    mentionlist.append(mentiontags)\n",
    "fbweekdata['User_mentions'] = mentionlist\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "datelist = []\n",
    "from datetime import datetime\n",
    "for tweet in fblist:\n",
    "    datestr = tweet['created_at']\n",
    "    # convert the key string to a datetime object\n",
    "    dt = datetime.strptime(datestr, \"%a %b %d %H:%M:%S +0000 %Y\")\n",
    "    datelist.append(dt)\n",
    "\n",
    "fbweekdata['datetime'] = datelist\n",
    "fbweekdata['yearmonthday'] = ['%d/%d/%d' % (dt.year,dt.month,dt.day) for dt in fbweekdata['datetime']]\n",
    "\n",
    "#Checking the dataframe\n",
    "print(fbweekdata.shape)\n",
    "print(fbweekdata.head())\n",
    "outfile = 'fbweekdata.csv'\n",
    "fbweekdata.to_csv(outfile, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for getting hashtags and mentions:\n",
    "def get_entities(tweet):\n",
    "    if 'entities' in tweet.keys():\n",
    "        mentions = [user_mention['screen_name'] for user_mention in tweet['entities']['user_mentions']]\n",
    "\n",
    "        hashtags = [hashtag['text'] for hashtag in tweet['entities']['hashtags']]\n",
    "\n",
    "\n",
    "        return mentions, hashtags\n",
    "    else:\n",
    "        # if no entities key, return empty lists\n",
    "        return [], []\n",
    "\n",
    "#List of top 20 frequently mentioned users:\n",
    "mention_fd = {}\n",
    "from operator import itemgetter\n",
    "for tweet in fblist:\n",
    "        # get the three entity lists from this tweet\n",
    "    (mentions, hashtags) = get_entities(tweet)\n",
    "        # put the mentions in the frequency dictionary\n",
    "    for tag in mentions:\n",
    "            # if the tag is not yet in the dictionary, add it with the count of 1\n",
    "        if not tag in mention_fd:\n",
    "                mention_fd[tag] = 1\n",
    "        else:\n",
    "                # otherwise, add 1 to the count that is already there\n",
    "                mention_fd[tag] += 1\n",
    "\n",
    "    # sort the dictionary by frequency values, returns a list of pairs of words and frequencies\n",
    "    #   in decreasing order\n",
    "mentions_sorted = sorted(mention_fd.items(), key=itemgetter(1), reverse=True)\n",
    "\n",
    "    # print out the top number of words with frequencies\n",
    "    # go through the first 20 tweets and find the entities\n",
    "print(\"Top\", 20, \"Frequency Mentions\")\n",
    "for (word, frequency) in mentions_sorted[:20]:\n",
    "    print (word, frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of top 20 frequently used Hashtags:\n",
    "hashtags_fd = {}\n",
    "for tweet in fblist:\n",
    "        # get the three entity lists from this tweet\n",
    "    (mentions, hashtags) = get_entities(tweet)\n",
    "        # put the hashtags in the frequency dictionary\n",
    "    hashlist = []\n",
    "    for tag in hashtags:\n",
    "        tag =tag.lower()\n",
    "        hashlist.append(tag)\n",
    "    for tag in hashlist:\n",
    "            # if the tag is not yet in the dictionary, add it with the count of 1\n",
    "        if not tag in hashtags_fd:\n",
    "                hashtags_fd[tag] = 1\n",
    "        else:\n",
    "                # otherwise, add 1 to the count that is already there\n",
    "                hashtags_fd[tag] += 1\n",
    "\n",
    "    # sort the dictionary by frequency values, returns a list of pairs of words and frequencies\n",
    "    #   in decreasing order\n",
    "hashtags_sorted = sorted(hashtags_fd.items(), key=itemgetter(1), reverse=True)\n",
    "\n",
    "    # print out the top number of words with frequencies\n",
    "    # go through the first 20 tweets and find the entities\n",
    "print(\"Top\", 20, \"Frequency Hashtags\")\n",
    "for (word, frequency) in hashtags_sorted[:20]:\n",
    "\n",
    "    print (word, frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorting the data according to the number of likes and retweets\n",
    "fbweekdata1 = fbweekdata\n",
    "Likelihood = (fbweekdata1.sort_values(by =['favorite_count'], ascending  = False))\n",
    "Retweeting = (fbweekdata1.sort_values(by =['retweet_count'], ascending  = False))\n",
    "Top20_tweets_by_likes = (Likelihood[['text', 'favorite_count', 'retweet_count']][:20])\n",
    "Top20_tweets_by_retweets = (Retweeting[['text','retweet_count', 'favorite_count']][:20])\n",
    "\n",
    "print(Top20_tweets_by_likes)\n",
    "print(Top20_tweets_by_retweets)\n",
    "\n",
    "#Printing the language in which tweets have been posted\n",
    "tweets_by_lang = fbweekdata['lang'].value_counts()\n",
    "print(tweets_by_lang)\n",
    "\n",
    "#Retrieving timezones of user profiles\n",
    "timezone = fbweekdata['usertimezone'].value_counts()\n",
    "print(timezone)\n",
    "\n",
    "#getting the list of timezone\n",
    "timezonelist = []\n",
    "count = 0\n",
    "for tweet in fblist:\n",
    "    if tweet['user']['time_zone'] != None:\n",
    "        timezonelist.append( tweet['user']['time_zone'])\n",
    "    else:\n",
    "        timezonelist.append(None)\n",
    "        count += 1\n",
    "\n",
    "#Count of users who have not mentioned their timezones\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating another dataframe to analyze data of 2 days\n",
    "fb2daydata = pd.DataFrame()\n",
    "\n",
    "fb2daydata['id'] = [tweet['id'] for tweet in fblist2]\n",
    "fb2daydata['text'] = [tweet['text'] for tweet in fblist2]\n",
    "fallondata['retweeted?'] = [tweet['retweeted'] for tweet in fallonlist]\n",
    "fb2daydata['lang'] = [tweet['lang'] for tweet in fblist2]\n",
    "fb2daydata['created_at'] = [tweet['created_at'] for tweet in fblist2]\n",
    "fb2daydata['retweet_count'] = [tweet['retweet_count'] for tweet in fblist2]\n",
    "fb2daydata['favorite_count'] = [tweet['favorite_count'] for tweet in fblist2]\n",
    "fb2daydata['username'] = [tweet['user']['name'] for tweet in fblist2]\n",
    "fb2daydata['SA'] = np.array([ analize_sentiment(tweet) for tweet in fb2daydata['text'] ])\n",
    "\n",
    "print(fb2daydata.head())\n",
    "\n",
    "#Using textblob library for Sentiment Analysis\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "\n",
    "def clean_tweet(tweet):\n",
    "    '''\n",
    "    Utility function to clean the text in a tweet by removing\n",
    "    links and special characters using regex.\n",
    "    '''\n",
    "    return ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
    "\n",
    "def analize_sentiment(tweet):\n",
    "    '''\n",
    "    Utility function to classify the polarity of a tweet\n",
    "    using textblob.\n",
    "    '''\n",
    "    analysis = TextBlob(clean_tweet(tweet))\n",
    "    if analysis.sentiment.polarity > 0:\n",
    "        return 1\n",
    "    elif analysis.sentiment.polarity == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return -1\n",
    "\n",
    "# We create a column with the result of the analysis:\n",
    "fbweekdata['SA'] = np.array([ analize_sentiment(tweet) for tweet in fbweekdata['text'] ])\n",
    "\n",
    "# We display the updated dataframe with the new column:\n",
    "print(fbweekdata.head(10))\n",
    "\n",
    "#Sentiment Analysis:\n",
    "# We construct lists with classified tweets:\n",
    "\n",
    "pos_tweets = [ tweet for index, tweet in enumerate(fb2daydata['text']) if fb2daydata['SA'][index] > 0]\n",
    "neu_tweets = [ tweet for index, tweet in enumerate(fb2daydata['text']) if fb2daydata['SA'][index] == 0]\n",
    "neg_tweets = [ tweet for index, tweet in enumerate(fb2daydata['text']) if fb2daydata['SA'][index] < 0]\n",
    "\n",
    "\n",
    "print(\"Percentage of positive tweets: {}%\".format(len(pos_tweets)*100/len(fb2daydata['text'])))\n",
    "print(\"Percentage of neutral tweets: {}%\".format(len(neu_tweets)*100/len(fb2daydata['text'])))\n",
    "print(\"Percentage de negative tweets: {}%\".format(len(neg_tweets)*100/len(fb2daydata['text'])))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
